{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Apply\" Function in PANDAS ~ df.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "# Loading Data\n",
    "dataset = load_dataset('lukebarousse/data_jobs')\n",
    "df = dataset['train'].to_pandas()\n",
    "\n",
    "# Data Cleanup\n",
    "df['job_posted_date'] = pd.to_datetime(df['job_posted_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. View the \"salary_year_avg\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        NaN\n",
       "1        NaN\n",
       "2        NaN\n",
       "3        NaN\n",
       "4        NaN\n",
       "          ..\n",
       "785736   NaN\n",
       "785737   NaN\n",
       "785738   NaN\n",
       "785739   NaN\n",
       "785740   NaN\n",
       "Name: salary_year_avg, Length: 785741, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['salary_year_avg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use pd.notna() function to remove NaN values from the \"salary\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28        109500.0\n",
       "77        140000.0\n",
       "92        120000.0\n",
       "100       228222.0\n",
       "109        89000.0\n",
       "            ...   \n",
       "785624    139216.0\n",
       "785641    150000.0\n",
       "785648    221875.0\n",
       "785682    157500.0\n",
       "785692    157500.0\n",
       "Name: salary_year_avg, Length: 22003, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[pd.notna(df['salary_year_avg'])]['salary_year_avg']\n",
    "# use notna() function first and then access the column later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Use help() function to get more information of the \"apply\" function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method apply in module pandas.core.frame:\n",
      "\n",
      "apply(func: 'AggFuncType', axis: 'Axis' = 0, raw: 'bool' = False, result_type: \"Literal['expand', 'reduce', 'broadcast'] | None\" = None, args=(), by_row: \"Literal[False, 'compat']\" = 'compat', engine: \"Literal['python', 'numba']\" = 'python', engine_kwargs: 'dict[str, bool] | None' = None, **kwargs) method of pandas.core.frame.DataFrame instance\n",
      "    Apply a function along an axis of the DataFrame.\n",
      "    \n",
      "    Objects passed to the function are Series objects whose index is\n",
      "    either the DataFrame's index (``axis=0``) or the DataFrame's columns\n",
      "    (``axis=1``). By default (``result_type=None``), the final return type\n",
      "    is inferred from the return type of the applied function. Otherwise,\n",
      "    it depends on the `result_type` argument.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    func : function\n",
      "        Function to apply to each column or row.\n",
      "    axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "        Axis along which the function is applied:\n",
      "    \n",
      "        * 0 or 'index': apply function to each column.\n",
      "        * 1 or 'columns': apply function to each row.\n",
      "    \n",
      "    raw : bool, default False\n",
      "        Determines if row or column is passed as a Series or ndarray object:\n",
      "    \n",
      "        * ``False`` : passes each row or column as a Series to the\n",
      "          function.\n",
      "        * ``True`` : the passed function will receive ndarray objects\n",
      "          instead.\n",
      "          If you are just applying a NumPy reduction function this will\n",
      "          achieve much better performance.\n",
      "    \n",
      "    result_type : {'expand', 'reduce', 'broadcast', None}, default None\n",
      "        These only act when ``axis=1`` (columns):\n",
      "    \n",
      "        * 'expand' : list-like results will be turned into columns.\n",
      "        * 'reduce' : returns a Series if possible rather than expanding\n",
      "          list-like results. This is the opposite of 'expand'.\n",
      "        * 'broadcast' : results will be broadcast to the original shape\n",
      "          of the DataFrame, the original index and columns will be\n",
      "          retained.\n",
      "    \n",
      "        The default behaviour (None) depends on the return value of the\n",
      "        applied function: list-like results will be returned as a Series\n",
      "        of those. However if the apply function returns a Series these\n",
      "        are expanded to columns.\n",
      "    args : tuple\n",
      "        Positional arguments to pass to `func` in addition to the\n",
      "        array/series.\n",
      "    by_row : False or \"compat\", default \"compat\"\n",
      "        Only has an effect when ``func`` is a listlike or dictlike of funcs\n",
      "        and the func isn't a string.\n",
      "        If \"compat\", will if possible first translate the func into pandas\n",
      "        methods (e.g. ``Series().apply(np.sum)`` will be translated to\n",
      "        ``Series().sum()``). If that doesn't work, will try call to apply again with\n",
      "        ``by_row=True`` and if that fails, will call apply again with\n",
      "        ``by_row=False`` (backward compatible).\n",
      "        If False, the funcs will be passed the whole Series at once.\n",
      "    \n",
      "        .. versionadded:: 2.1.0\n",
      "    \n",
      "    engine : {'python', 'numba'}, default 'python'\n",
      "        Choose between the python (default) engine or the numba engine in apply.\n",
      "    \n",
      "        The numba engine will attempt to JIT compile the passed function,\n",
      "        which may result in speedups for large DataFrames.\n",
      "        It also supports the following engine_kwargs :\n",
      "    \n",
      "        - nopython (compile the function in nopython mode)\n",
      "        - nogil (release the GIL inside the JIT compiled function)\n",
      "        - parallel (try to apply the function in parallel over the DataFrame)\n",
      "    \n",
      "          Note: Due to limitations within numba/how pandas interfaces with numba,\n",
      "          you should only use this if raw=True\n",
      "    \n",
      "        Note: The numba compiler only supports a subset of\n",
      "        valid Python/numpy operations.\n",
      "    \n",
      "        Please read more about the `supported python features\n",
      "        <https://numba.pydata.org/numba-doc/dev/reference/pysupported.html>`_\n",
      "        and `supported numpy features\n",
      "        <https://numba.pydata.org/numba-doc/dev/reference/numpysupported.html>`_\n",
      "        in numba to learn what you can or cannot use in the passed function.\n",
      "    \n",
      "        .. versionadded:: 2.2.0\n",
      "    \n",
      "    engine_kwargs : dict\n",
      "        Pass keyword arguments to the engine.\n",
      "        This is currently only used by the numba engine,\n",
      "        see the documentation for the engine argument for more information.\n",
      "    **kwargs\n",
      "        Additional keyword arguments to pass as keywords arguments to\n",
      "        `func`.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    Series or DataFrame\n",
      "        Result of applying ``func`` along the given axis of the\n",
      "        DataFrame.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.map: For elementwise operations.\n",
      "    DataFrame.aggregate: Only perform aggregating type operations.\n",
      "    DataFrame.transform: Only perform transforming type operations.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Functions that mutate the passed object can produce unexpected\n",
      "    behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
      "    for more details.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame([[4, 9]] * 3, columns=['A', 'B'])\n",
      "    >>> df\n",
      "       A  B\n",
      "    0  4  9\n",
      "    1  4  9\n",
      "    2  4  9\n",
      "    \n",
      "    Using a numpy universal function (in this case the same as\n",
      "    ``np.sqrt(df)``):\n",
      "    \n",
      "    >>> df.apply(np.sqrt)\n",
      "         A    B\n",
      "    0  2.0  3.0\n",
      "    1  2.0  3.0\n",
      "    2  2.0  3.0\n",
      "    \n",
      "    Using a reducing function on either axis\n",
      "    \n",
      "    >>> df.apply(np.sum, axis=0)\n",
      "    A    12\n",
      "    B    27\n",
      "    dtype: int64\n",
      "    \n",
      "    >>> df.apply(np.sum, axis=1)\n",
      "    0    13\n",
      "    1    13\n",
      "    2    13\n",
      "    dtype: int64\n",
      "    \n",
      "    Returning a list-like will result in a Series\n",
      "    \n",
      "    >>> df.apply(lambda x: [1, 2], axis=1)\n",
      "    0    [1, 2]\n",
      "    1    [1, 2]\n",
      "    2    [1, 2]\n",
      "    dtype: object\n",
      "    \n",
      "    Passing ``result_type='expand'`` will expand list-like results\n",
      "    to columns of a Dataframe\n",
      "    \n",
      "    >>> df.apply(lambda x: [1, 2], axis=1, result_type='expand')\n",
      "       0  1\n",
      "    0  1  2\n",
      "    1  1  2\n",
      "    2  1  2\n",
      "    \n",
      "    Returning a Series inside the function is similar to passing\n",
      "    ``result_type='expand'``. The resulting column names\n",
      "    will be the Series index.\n",
      "    \n",
      "    >>> df.apply(lambda x: pd.Series([1, 2], index=['foo', 'bar']), axis=1)\n",
      "       foo  bar\n",
      "    0    1    2\n",
      "    1    1    2\n",
      "    2    1    2\n",
      "    \n",
      "    Passing ``result_type='broadcast'`` will ensure the same shape\n",
      "    result, whether list-like or scalar is returned by the function,\n",
      "    and broadcast it along the axis. The resulting column names will\n",
      "    be the originals.\n",
      "    \n",
      "    >>> df.apply(lambda x: [1, 2], axis=1, result_type='broadcast')\n",
      "       A  B\n",
      "    0  1  2\n",
      "    1  1  2\n",
      "    2  1  2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(df.apply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create a function to calculate projected salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_year_inflated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>109500.0</td>\n",
       "      <td>112785.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>140000.0</td>\n",
       "      <td>144200.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>123600.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>228222.0</td>\n",
       "      <td>235068.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>89000.0</td>\n",
       "      <td>91670.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785624</th>\n",
       "      <td>139216.0</td>\n",
       "      <td>143392.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785641</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>154500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785648</th>\n",
       "      <td>221875.0</td>\n",
       "      <td>228531.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785682</th>\n",
       "      <td>157500.0</td>\n",
       "      <td>162225.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785692</th>\n",
       "      <td>157500.0</td>\n",
       "      <td>162225.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22003 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        salary_year_avg  salary_year_inflated\n",
       "28             109500.0             112785.00\n",
       "77             140000.0             144200.00\n",
       "92             120000.0             123600.00\n",
       "100            228222.0             235068.66\n",
       "109             89000.0              91670.00\n",
       "...                 ...                   ...\n",
       "785624         139216.0             143392.48\n",
       "785641         150000.0             154500.00\n",
       "785648         221875.0             228531.25\n",
       "785682         157500.0             162225.00\n",
       "785692         157500.0             162225.00\n",
       "\n",
       "[22003 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_salary = df[pd.notna(df['salary_year_avg'])].copy()\n",
    "def projected_salary(salary):\n",
    "    return salary * 1.03\n",
    "\n",
    "df_salary['salary_year_inflated'] = df_salary['salary_year_avg'].apply(projected_salary) # just provide the name of the fx\n",
    "df_salary[['salary_year_avg','salary_year_inflated']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> so using this 'apply' function is like creating a new calculated column in Power Pivot, we can manipulate values of the other columns and put it into a new column "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Use Lambda function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_year_inflated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>109500.0</td>\n",
       "      <td>112785.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>140000.0</td>\n",
       "      <td>144200.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>123600.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>228222.0</td>\n",
       "      <td>235068.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>89000.0</td>\n",
       "      <td>91670.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785624</th>\n",
       "      <td>139216.0</td>\n",
       "      <td>143392.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785641</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>154500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785648</th>\n",
       "      <td>221875.0</td>\n",
       "      <td>228531.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785682</th>\n",
       "      <td>157500.0</td>\n",
       "      <td>162225.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785692</th>\n",
       "      <td>157500.0</td>\n",
       "      <td>162225.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22003 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        salary_year_avg  salary_year_inflated\n",
       "28             109500.0             112785.00\n",
       "77             140000.0             144200.00\n",
       "92             120000.0             123600.00\n",
       "100            228222.0             235068.66\n",
       "109             89000.0              91670.00\n",
       "...                 ...                   ...\n",
       "785624         139216.0             143392.48\n",
       "785641         150000.0             154500.00\n",
       "785648         221875.0             228531.25\n",
       "785682         157500.0             162225.00\n",
       "785692         157500.0             162225.00\n",
       "\n",
       "[22003 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_salary2 = df[pd.notna(df['salary_year_avg'])].copy()\n",
    "df_salary2['salary_year_inflated'] = df_salary2['salary_year_avg'].apply(lambda salary : salary * 1.03)\n",
    "df_salary2[['salary_year_avg','salary_year_inflated']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Another approach instead of apply function and lambda function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_year_inflated2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>109500.0</td>\n",
       "      <td>112785.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>140000.0</td>\n",
       "      <td>144200.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>123600.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>228222.0</td>\n",
       "      <td>235068.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>89000.0</td>\n",
       "      <td>91670.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785624</th>\n",
       "      <td>139216.0</td>\n",
       "      <td>143392.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785641</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>154500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785648</th>\n",
       "      <td>221875.0</td>\n",
       "      <td>228531.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785682</th>\n",
       "      <td>157500.0</td>\n",
       "      <td>162225.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785692</th>\n",
       "      <td>157500.0</td>\n",
       "      <td>162225.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22003 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        salary_year_avg  salary_year_inflated2\n",
       "28             109500.0              112785.00\n",
       "77             140000.0              144200.00\n",
       "92             120000.0              123600.00\n",
       "100            228222.0              235068.66\n",
       "109             89000.0               91670.00\n",
       "...                 ...                    ...\n",
       "785624         139216.0              143392.48\n",
       "785641         150000.0              154500.00\n",
       "785648         221875.0              228531.25\n",
       "785682         157500.0              162225.00\n",
       "785692         157500.0              162225.00\n",
       "\n",
       "[22003 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_salary2['salary_year_inflated2'] = df_salary2['salary_year_avg'] * 1.03\n",
    "\n",
    "df_salary2[['salary_year_avg','salary_year_inflated2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Convert string data to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['job_skills'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- use the list function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " \"'\",\n",
       " 'r',\n",
       " \"'\",\n",
       " ',',\n",
       " ' ',\n",
       " \"'\",\n",
       " 'p',\n",
       " 'y',\n",
       " 't',\n",
       " 'h',\n",
       " 'o',\n",
       " 'n',\n",
       " \"'\",\n",
       " ',',\n",
       " ' ',\n",
       " \"'\",\n",
       " 's',\n",
       " 'q',\n",
       " 'l',\n",
       " \"'\",\n",
       " ',',\n",
       " ' ',\n",
       " \"'\",\n",
       " 'n',\n",
       " 'o',\n",
       " 's',\n",
       " 'q',\n",
       " 'l',\n",
       " \"'\",\n",
       " ',',\n",
       " ' ',\n",
       " \"'\",\n",
       " 'p',\n",
       " 'o',\n",
       " 'w',\n",
       " 'e',\n",
       " 'r',\n",
       " ' ',\n",
       " 'b',\n",
       " 'i',\n",
       " \"'\",\n",
       " ',',\n",
       " ' ',\n",
       " \"'\",\n",
       " 't',\n",
       " 'a',\n",
       " 'b',\n",
       " 'l',\n",
       " 'e',\n",
       " 'a',\n",
       " 'u',\n",
       " \"'\",\n",
       " ']']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df['job_skills'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> this \"list\" function does not work as we want so we look for another one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- behold the ast.literal_eval() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "job_skills = ast.literal_eval(df['job_skills'][1])\n",
    "job_skills\n",
    "type(job_skills)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- run this function on the entire column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "malformed node or string: 0                                                      None\n1         ['r', 'python', 'sql', 'nosql', 'power bi', 't...\n2         ['python', 'sql', 'c#', 'azure', 'airflow', 'd...\n3         ['python', 'c++', 'java', 'matlab', 'aws', 'te...\n4         ['bash', 'python', 'oracle', 'aws', 'ansible',...\n                                ...                        \n785736    ['bash', 'python', 'perl', 'linux', 'unix', 'k...\n785737                       ['sas', 'sas', 'sql', 'excel']\n785738                              ['powerpoint', 'excel']\n785739    ['python', 'go', 'nosql', 'sql', 'mongo', 'she...\n785740                                      ['aws', 'flow']\nName: job_skills, Length: 785741, dtype: object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjob_skills\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mliteral_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjob_skills\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Pham Duc Toan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ast.py:110\u001b[0m, in \u001b[0;36mliteral_eval\u001b[1;34m(node_or_string)\u001b[0m\n\u001b[0;32m    108\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m left \u001b[38;5;241m-\u001b[39m right\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _convert_signed_num(node)\n\u001b[1;32m--> 110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_or_string\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Pham Duc Toan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ast.py:109\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    108\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m left \u001b[38;5;241m-\u001b[39m right\n\u001b[1;32m--> 109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert_signed_num\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Pham Duc Toan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ast.py:83\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_signed_num\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     82\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m operand\n\u001b[1;32m---> 83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert_num\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Pham Duc Toan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ast.py:74\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_num\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_convert_num\u001b[39m(node):\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, Constant) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(node\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mcomplex\u001b[39m):\n\u001b[1;32m---> 74\u001b[0m         \u001b[43m_raise_malformed_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m node\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[1;32mc:\\Users\\Pham Duc Toan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ast.py:71\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._raise_malformed_node\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lno \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(node, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlineno\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     70\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m on line \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlno\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 71\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: malformed node or string: 0                                                      None\n1         ['r', 'python', 'sql', 'nosql', 'power bi', 't...\n2         ['python', 'sql', 'c#', 'azure', 'airflow', 'd...\n3         ['python', 'c++', 'java', 'matlab', 'aws', 'te...\n4         ['bash', 'python', 'oracle', 'aws', 'ansible',...\n                                ...                        \n785736    ['bash', 'python', 'perl', 'linux', 'unix', 'k...\n785737                       ['sas', 'sas', 'sql', 'excel']\n785738                              ['powerpoint', 'excel']\n785739    ['python', 'go', 'nosql', 'sql', 'mongo', 'she...\n785740                                      ['aws', 'flow']\nName: job_skills, Length: 785741, dtype: object"
     ]
    }
   ],
   "source": [
    "\n",
    "df['job_skills'] = ast.literal_eval(df['job_skills'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> errrrorrrr, we have to create a new function and use apply function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- APPLY this function on the entire column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_list(skill_list):\n",
    "    if pd.notna(skill_list): # if the value in any row is None, skip the row\n",
    "        return ast.literal_eval(skill_list)\n",
    "\n",
    "df2 = df.copy()\n",
    "df2['job_skills'] = df2['job_skills'].apply(clean_list) # remember there's no parentheses guys\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df2['job_skills'][1]) # index 0 is Null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use Lambda function inside the apply function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.copy()\n",
    "df3['job_skills'] = df3['job_skills'].apply(lambda skill_list: ast.literal_eval(skill_list) if pd.notna(skill_list) else skill_list)\n",
    "# that's how to apply conditional calculation inside the lambda function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['r', 'python', 'sql', 'nosql', 'power bi', 'tableau']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['job_skills'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Lambda is pretty important and will be seen in the next section, stay tuned baby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Use \"apply\" function to access rows instead columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are calculating projected salary on:\n",
    "- Senior roles, assume a 5% increase\n",
    "- Other roles, assume a 3% increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salary3 = df[pd.notna(df['salary_year_avg'])].copy()\n",
    "\n",
    "def projected_salary(row): # the argument passed into this function is a whole row instead of a single value\n",
    "    if \"Senior\" in row['job_title_short']: # get value in a specified column \n",
    "        return row['salary_year_avg'] * 1.05\n",
    "    else:\n",
    "        return row['salary_year_avg'] * 1.03\n",
    "\n",
    "df_salary3['salary_year_inflated'] = df_salary3.apply(projected_salary, axis = 1)\n",
    "# the diff here is we dont access any column before using the apply function\n",
    "df_salary3.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do it the \"Lambda\" way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title_short</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_via</th>\n",
       "      <th>job_schedule_type</th>\n",
       "      <th>job_work_from_home</th>\n",
       "      <th>search_location</th>\n",
       "      <th>job_posted_date</th>\n",
       "      <th>job_no_degree_mention</th>\n",
       "      <th>job_health_insurance</th>\n",
       "      <th>job_country</th>\n",
       "      <th>salary_rate</th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_hour_avg</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>job_type_skills</th>\n",
       "      <th>salary_year_inflated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>762660</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>San Bruno, CA</td>\n",
       "      <td>via Indeed</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>California, United States</td>\n",
       "      <td>2023-05-04 20:01:17</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>year</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LatentView Analytics</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>92700.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783761</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>True</td>\n",
       "      <td>Texas, United States</td>\n",
       "      <td>2023-01-04 15:37:16</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>year</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Elsdon Consulting ltd</td>\n",
       "      <td>['azure', 'power bi']</td>\n",
       "      <td>{'analyst_tools': ['power bi'], 'cloud': ['azu...</td>\n",
       "      <td>136500.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608014</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Senior/Lead Data Scientist</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>via Ladders</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>California, United States</td>\n",
       "      <td>2023-10-24 09:03:33</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>year</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Susa Ventures</td>\n",
       "      <td>['sql', 'python', 'pyspark', 'unify']</td>\n",
       "      <td>{'libraries': ['pyspark'], 'programming': ['sq...</td>\n",
       "      <td>94500.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52854</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Help Desk Analyst II</td>\n",
       "      <td>Indianapolis, IN</td>\n",
       "      <td>via SonicJobs</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Illinois, United States</td>\n",
       "      <td>2023-04-20 06:01:18</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>year</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Robert Half</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>51500.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739223</th>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>BI Developer</td>\n",
       "      <td>New Delhi, Delhi, India</td>\n",
       "      <td>via Ai-Jobs.net</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>India</td>\n",
       "      <td>2023-01-30 21:11:50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>India</td>\n",
       "      <td>year</td>\n",
       "      <td>79200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Armis Security</td>\n",
       "      <td>['sql', 'python', 'java', 'snowflake', 'aws', ...</td>\n",
       "      <td>{'cloud': ['snowflake', 'aws', 'azure'], 'prog...</td>\n",
       "      <td>81576.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751292</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Senior Data Scientist, End to End Data Systems</td>\n",
       "      <td>Santa Clara, CA</td>\n",
       "      <td>via Indeed</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>California, United States</td>\n",
       "      <td>2023-08-23 20:03:44</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>year</td>\n",
       "      <td>203625.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>['sql', 'python', 'cassandra', 'spark', 'hadoop']</td>\n",
       "      <td>{'databases': ['cassandra'], 'libraries': ['sp...</td>\n",
       "      <td>213806.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190292</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>None</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>New York, United States</td>\n",
       "      <td>2023-06-23 15:00:03</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>United States</td>\n",
       "      <td>year</td>\n",
       "      <td>122500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Synechron</td>\n",
       "      <td>['sql', 'python', 'spreadsheet', 'excel', 'alt...</td>\n",
       "      <td>{'analyst_tools': ['spreadsheet', 'excel', 'al...</td>\n",
       "      <td>128625.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630429</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>2023-11-01 12:39:35</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>year</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YES! Communities</td>\n",
       "      <td>['python', 'r', 'sql']</td>\n",
       "      <td>{'programming': ['python', 'r', 'sql']}</td>\n",
       "      <td>133900.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120463</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>El Segundo, CA</td>\n",
       "      <td>via Ladders</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>California, United States</td>\n",
       "      <td>2023-06-06 08:03:10</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>United States</td>\n",
       "      <td>year</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Aerospace Corporation</td>\n",
       "      <td>['python', 'docker', 'kubernetes']</td>\n",
       "      <td>{'other': ['docker', 'kubernetes'], 'programmi...</td>\n",
       "      <td>154500.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498549</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>True</td>\n",
       "      <td>Texas, United States</td>\n",
       "      <td>2023-12-07 11:09:30</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>United States</td>\n",
       "      <td>year</td>\n",
       "      <td>151500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ARC IT Recruitment</td>\n",
       "      <td>['python', 'aws', 'gcp', 'azure', 'airflow', '...</td>\n",
       "      <td>{'cloud': ['aws', 'gcp', 'azure'], 'libraries'...</td>\n",
       "      <td>159075.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253169</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Lead Data Engineer</td>\n",
       "      <td>Calgary, AB, Canada</td>\n",
       "      <td>via Ladders</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2023-01-19 08:00:42</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Canada</td>\n",
       "      <td>year</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RBC</td>\n",
       "      <td>['java', 'scala', 'sql', 'nosql', 'azure', 'aw...</td>\n",
       "      <td>{'cloud': ['azure', 'aws'], 'libraries': ['spr...</td>\n",
       "      <td>92700.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182637</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>via ZipRecruiter</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>New York, United States</td>\n",
       "      <td>2023-07-25 15:00:50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>year</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Imagine One Technology &amp; Management</td>\n",
       "      <td>['python', 'qlik', 'tableau', 'spss', 'word', ...</td>\n",
       "      <td>{'analyst_tools': ['qlik', 'tableau', 'spss', ...</td>\n",
       "      <td>115500.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617916</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Machine Learning Expert</td>\n",
       "      <td>Brussels, Belgium</td>\n",
       "      <td>via Ai-Jobs.net</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>2023-03-08 12:11:06</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>year</td>\n",
       "      <td>72900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Uni Systems</td>\n",
       "      <td>['perl', 'python', 'matlab', 'r', 'sql', 'nosq...</td>\n",
       "      <td>{'cloud': ['aws', 'azure'], 'databases': ['mon...</td>\n",
       "      <td>75087.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747774</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Director of Data Science (Insurance Underwriting)</td>\n",
       "      <td>United States</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Illinois, United States</td>\n",
       "      <td>2023-01-04 20:05:55</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>United States</td>\n",
       "      <td>year</td>\n",
       "      <td>222500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Averity</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>229175.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490851</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>via Indeed</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>2023-06-14 11:46:36</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>United States</td>\n",
       "      <td>year</td>\n",
       "      <td>170000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harnham</td>\n",
       "      <td>['python', 'scala', 'azure', 'hadoop', 'spark'...</td>\n",
       "      <td>{'cloud': ['azure'], 'libraries': ['hadoop', '...</td>\n",
       "      <td>178500.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287131</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Senior Manager of Data Science</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>True</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>2023-01-17 17:50:02</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>year</td>\n",
       "      <td>165000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harnham</td>\n",
       "      <td>['sql', 'python', 'sas', 'sas', 'watson', 'exc...</td>\n",
       "      <td>{'analyst_tools': ['sas', 'excel', 'tableau', ...</td>\n",
       "      <td>173250.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542392</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Forensic Data Analyst</td>\n",
       "      <td>St. Louis, MO</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Illinois, United States</td>\n",
       "      <td>2023-10-03 19:01:37</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>United States</td>\n",
       "      <td>year</td>\n",
       "      <td>100774.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>National Geospatial-Intelligence Agency</td>\n",
       "      <td>['c', 'python', 'sql', 'tableau', 'spss', 'exc...</td>\n",
       "      <td>{'analyst_tools': ['tableau', 'spss', 'excel']...</td>\n",
       "      <td>103797.735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421402</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Illinois, United States</td>\n",
       "      <td>2023-01-04 16:31:27</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>year</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EdgeLink</td>\n",
       "      <td>['sql', 'python', 'sql server', 'databricks', ...</td>\n",
       "      <td>{'analyst_tools': ['power bi'], 'cloud': ['dat...</td>\n",
       "      <td>118450.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648992</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist, Product Analytics</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>via Ladders</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>New York, United States</td>\n",
       "      <td>2023-07-25 12:03:02</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>United States</td>\n",
       "      <td>year</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Citizen.com</td>\n",
       "      <td>['sql', 'python', 'r', 'bigquery', 'tableau', ...</td>\n",
       "      <td>{'analyst_tools': ['tableau', 'sheets'], 'clou...</td>\n",
       "      <td>154500.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525704</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>via JobServe</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>2023-07-27 11:55:45</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>United States</td>\n",
       "      <td>year</td>\n",
       "      <td>174720.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Disney Media &amp; Entertainment Distribution</td>\n",
       "      <td>['python', 'sql', 'databricks', 'snowflake', '...</td>\n",
       "      <td>{'analyst_tools': ['tableau', 'looker'], 'clou...</td>\n",
       "      <td>179961.600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  job_title_short  \\\n",
       "762660               Data Analyst   \n",
       "783761       Senior Data Engineer   \n",
       "608014      Senior Data Scientist   \n",
       "52854               Data Engineer   \n",
       "739223          Software Engineer   \n",
       "751292      Senior Data Scientist   \n",
       "190292        Senior Data Analyst   \n",
       "630429             Data Scientist   \n",
       "120463             Data Scientist   \n",
       "498549       Senior Data Engineer   \n",
       "253169              Data Engineer   \n",
       "182637        Senior Data Analyst   \n",
       "617916  Machine Learning Engineer   \n",
       "747774             Data Scientist   \n",
       "490851       Senior Data Engineer   \n",
       "287131      Senior Data Scientist   \n",
       "542392               Data Analyst   \n",
       "421402              Data Engineer   \n",
       "648992             Data Scientist   \n",
       "525704             Data Scientist   \n",
       "\n",
       "                                                job_title  \\\n",
       "762660                                       Data Analyst   \n",
       "783761                               Senior Data Engineer   \n",
       "608014                         Senior/Lead Data Scientist   \n",
       "52854                                Help Desk Analyst II   \n",
       "739223                                       BI Developer   \n",
       "751292     Senior Data Scientist, End to End Data Systems   \n",
       "190292                                Senior Data Analyst   \n",
       "630429                           Principal Data Scientist   \n",
       "120463                                     Data Scientist   \n",
       "498549                               Senior Data Engineer   \n",
       "253169                                 Lead Data Engineer   \n",
       "182637                                Senior Data Analyst   \n",
       "617916                            Machine Learning Expert   \n",
       "747774  Director of Data Science (Insurance Underwriting)   \n",
       "490851                               Senior Data Engineer   \n",
       "287131                     Senior Manager of Data Science   \n",
       "542392                              Forensic Data Analyst   \n",
       "421402                                      Data Engineer   \n",
       "648992                  Data Scientist, Product Analytics   \n",
       "525704                                Lead Data Scientist   \n",
       "\n",
       "                   job_location           job_via job_schedule_type  \\\n",
       "762660            San Bruno, CA        via Indeed         Full-time   \n",
       "783761                 Anywhere      via LinkedIn         Full-time   \n",
       "608014        San Francisco, CA       via Ladders         Full-time   \n",
       "52854          Indianapolis, IN     via SonicJobs         Full-time   \n",
       "739223  New Delhi, Delhi, India   via Ai-Jobs.net         Full-time   \n",
       "751292          Santa Clara, CA        via Indeed         Full-time   \n",
       "190292                     None      via LinkedIn         Full-time   \n",
       "630429                 Colorado      via LinkedIn         Full-time   \n",
       "120463           El Segundo, CA       via Ladders         Full-time   \n",
       "498549                 Anywhere      via LinkedIn         Full-time   \n",
       "253169      Calgary, AB, Canada       via Ladders         Full-time   \n",
       "182637           Washington, DC  via ZipRecruiter         Full-time   \n",
       "617916        Brussels, Belgium   via Ai-Jobs.net         Full-time   \n",
       "747774            United States      via LinkedIn         Full-time   \n",
       "490851        San Francisco, CA        via Indeed         Full-time   \n",
       "287131                 Anywhere      via LinkedIn         Full-time   \n",
       "542392            St. Louis, MO      via LinkedIn         Full-time   \n",
       "421402               Denver, CO      via LinkedIn         Full-time   \n",
       "648992             New York, NY       via Ladders         Full-time   \n",
       "525704              Atlanta, GA      via JobServe         Full-time   \n",
       "\n",
       "        job_work_from_home            search_location     job_posted_date  \\\n",
       "762660               False  California, United States 2023-05-04 20:01:17   \n",
       "783761                True       Texas, United States 2023-01-04 15:37:16   \n",
       "608014               False  California, United States 2023-10-24 09:03:33   \n",
       "52854                False    Illinois, United States 2023-04-20 06:01:18   \n",
       "739223               False                      India 2023-01-30 21:11:50   \n",
       "751292               False  California, United States 2023-08-23 20:03:44   \n",
       "190292               False    New York, United States 2023-06-23 15:00:03   \n",
       "630429               False                      Sudan 2023-11-01 12:39:35   \n",
       "120463               False  California, United States 2023-06-06 08:03:10   \n",
       "498549                True       Texas, United States 2023-12-07 11:09:30   \n",
       "253169               False                     Canada 2023-01-19 08:00:42   \n",
       "182637               False    New York, United States 2023-07-25 15:00:50   \n",
       "617916               False                    Belgium 2023-03-08 12:11:06   \n",
       "747774               False    Illinois, United States 2023-01-04 20:05:55   \n",
       "490851               False                    Georgia 2023-06-14 11:46:36   \n",
       "287131                True                      Sudan 2023-01-17 17:50:02   \n",
       "542392               False    Illinois, United States 2023-10-03 19:01:37   \n",
       "421402               False    Illinois, United States 2023-01-04 16:31:27   \n",
       "648992               False    New York, United States 2023-07-25 12:03:02   \n",
       "525704               False                    Georgia 2023-07-27 11:55:45   \n",
       "\n",
       "        job_no_degree_mention  job_health_insurance    job_country  \\\n",
       "762660                   True                 False  United States   \n",
       "783761                  False                 False  United States   \n",
       "608014                  False                 False  United States   \n",
       "52854                    True                 False  United States   \n",
       "739223                  False                 False          India   \n",
       "751292                  False                 False  United States   \n",
       "190292                  False                  True  United States   \n",
       "630429                  False                 False          Sudan   \n",
       "120463                  False                  True  United States   \n",
       "498549                  False                  True  United States   \n",
       "253169                  False                 False         Canada   \n",
       "182637                  False                 False  United States   \n",
       "617916                  False                 False        Belgium   \n",
       "747774                   True                  True  United States   \n",
       "490851                   True                  True  United States   \n",
       "287131                  False                 False          Sudan   \n",
       "542392                  False                  True  United States   \n",
       "421402                  False                 False  United States   \n",
       "648992                  False                  True  United States   \n",
       "525704                  False                  True  United States   \n",
       "\n",
       "       salary_rate  salary_year_avg  salary_hour_avg  \\\n",
       "762660        year          90000.0              NaN   \n",
       "783761        year         130000.0              NaN   \n",
       "608014        year          90000.0              NaN   \n",
       "52854         year          50000.0              NaN   \n",
       "739223        year          79200.0              NaN   \n",
       "751292        year         203625.0              NaN   \n",
       "190292        year         122500.0              NaN   \n",
       "630429        year         130000.0              NaN   \n",
       "120463        year         150000.0              NaN   \n",
       "498549        year         151500.0              NaN   \n",
       "253169        year          90000.0              NaN   \n",
       "182637        year         110000.0              NaN   \n",
       "617916        year          72900.0              NaN   \n",
       "747774        year         222500.0              NaN   \n",
       "490851        year         170000.0              NaN   \n",
       "287131        year         165000.0              NaN   \n",
       "542392        year         100774.5              NaN   \n",
       "421402        year         115000.0              NaN   \n",
       "648992        year         150000.0              NaN   \n",
       "525704        year         174720.0              NaN   \n",
       "\n",
       "                                     company_name  \\\n",
       "762660                       LatentView Analytics   \n",
       "783761                      Elsdon Consulting ltd   \n",
       "608014                              Susa Ventures   \n",
       "52854                                 Robert Half   \n",
       "739223                             Armis Security   \n",
       "751292                                     NVIDIA   \n",
       "190292                                  Synechron   \n",
       "630429                           YES! Communities   \n",
       "120463                  The Aerospace Corporation   \n",
       "498549                         ARC IT Recruitment   \n",
       "253169                                        RBC   \n",
       "182637        Imagine One Technology & Management   \n",
       "617916                                Uni Systems   \n",
       "747774                                    Averity   \n",
       "490851                                    Harnham   \n",
       "287131                                    Harnham   \n",
       "542392    National Geospatial-Intelligence Agency   \n",
       "421402                                   EdgeLink   \n",
       "648992                                Citizen.com   \n",
       "525704  Disney Media & Entertainment Distribution   \n",
       "\n",
       "                                               job_skills  \\\n",
       "762660                                               None   \n",
       "783761                              ['azure', 'power bi']   \n",
       "608014              ['sql', 'python', 'pyspark', 'unify']   \n",
       "52854                                                None   \n",
       "739223  ['sql', 'python', 'java', 'snowflake', 'aws', ...   \n",
       "751292  ['sql', 'python', 'cassandra', 'spark', 'hadoop']   \n",
       "190292  ['sql', 'python', 'spreadsheet', 'excel', 'alt...   \n",
       "630429                             ['python', 'r', 'sql']   \n",
       "120463                 ['python', 'docker', 'kubernetes']   \n",
       "498549  ['python', 'aws', 'gcp', 'azure', 'airflow', '...   \n",
       "253169  ['java', 'scala', 'sql', 'nosql', 'azure', 'aw...   \n",
       "182637  ['python', 'qlik', 'tableau', 'spss', 'word', ...   \n",
       "617916  ['perl', 'python', 'matlab', 'r', 'sql', 'nosq...   \n",
       "747774                                               None   \n",
       "490851  ['python', 'scala', 'azure', 'hadoop', 'spark'...   \n",
       "287131  ['sql', 'python', 'sas', 'sas', 'watson', 'exc...   \n",
       "542392  ['c', 'python', 'sql', 'tableau', 'spss', 'exc...   \n",
       "421402  ['sql', 'python', 'sql server', 'databricks', ...   \n",
       "648992  ['sql', 'python', 'r', 'bigquery', 'tableau', ...   \n",
       "525704  ['python', 'sql', 'databricks', 'snowflake', '...   \n",
       "\n",
       "                                          job_type_skills  \\\n",
       "762660                                               None   \n",
       "783761  {'analyst_tools': ['power bi'], 'cloud': ['azu...   \n",
       "608014  {'libraries': ['pyspark'], 'programming': ['sq...   \n",
       "52854                                                None   \n",
       "739223  {'cloud': ['snowflake', 'aws', 'azure'], 'prog...   \n",
       "751292  {'databases': ['cassandra'], 'libraries': ['sp...   \n",
       "190292  {'analyst_tools': ['spreadsheet', 'excel', 'al...   \n",
       "630429            {'programming': ['python', 'r', 'sql']}   \n",
       "120463  {'other': ['docker', 'kubernetes'], 'programmi...   \n",
       "498549  {'cloud': ['aws', 'gcp', 'azure'], 'libraries'...   \n",
       "253169  {'cloud': ['azure', 'aws'], 'libraries': ['spr...   \n",
       "182637  {'analyst_tools': ['qlik', 'tableau', 'spss', ...   \n",
       "617916  {'cloud': ['aws', 'azure'], 'databases': ['mon...   \n",
       "747774                                               None   \n",
       "490851  {'cloud': ['azure'], 'libraries': ['hadoop', '...   \n",
       "287131  {'analyst_tools': ['sas', 'excel', 'tableau', ...   \n",
       "542392  {'analyst_tools': ['tableau', 'spss', 'excel']...   \n",
       "421402  {'analyst_tools': ['power bi'], 'cloud': ['dat...   \n",
       "648992  {'analyst_tools': ['tableau', 'sheets'], 'clou...   \n",
       "525704  {'analyst_tools': ['tableau', 'looker'], 'clou...   \n",
       "\n",
       "        salary_year_inflated  \n",
       "762660             92700.000  \n",
       "783761            136500.000  \n",
       "608014             94500.000  \n",
       "52854              51500.000  \n",
       "739223             81576.000  \n",
       "751292            213806.250  \n",
       "190292            128625.000  \n",
       "630429            133900.000  \n",
       "120463            154500.000  \n",
       "498549            159075.000  \n",
       "253169             92700.000  \n",
       "182637            115500.000  \n",
       "617916             75087.000  \n",
       "747774            229175.000  \n",
       "490851            178500.000  \n",
       "287131            173250.000  \n",
       "542392            103797.735  \n",
       "421402            118450.000  \n",
       "648992            154500.000  \n",
       "525704            179961.600  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_salary3 = df[pd.notna(df['salary_year_avg'])].copy()\n",
    "df_salary3['salary_year_inflated'] = df_salary3.apply(lambda row : 1.05 *row['salary_year_avg'] if \"Senior\" in row['job_title_short'] else 1.03 * row ['salary_year_avg']  , axis = 1)\n",
    "\n",
    "df_salary3.sample(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
